{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7de79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import zipfile\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "if not os.path.ismount('/content/drive'):\n",
    "    drive.mount('/content/drive')\n",
    "else:\n",
    "    print(\"Google Drive is already mounted.\")\n",
    "\n",
    "zip_path = '/content/drive/MyDrive/Attendance_Checkpoints/Copy of Attendance_Checkpoints.zip'\n",
    "extract_dir = '/content/Attendance_Dataset'\n",
    "checkpoint_dir = '/content/drive/MyDrive/Attendance_Checkpoints'\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "    print(\"Dataset extracted successfully.\")\n",
    "\n",
    "base_dir = extract_dir\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "augmented_train_dir = os.path.join(base_dir, 'Augmented_Train')\n",
    "val_dir = os.path.join(base_dir, 'validation')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "if not all(os.path.exists(d) for d in [train_dir, val_dir, test_dir]):\n",
    "    raise ValueError(\"One or more dataset directories are missing after extraction. Please check the zip content.\")\n",
    "\n",
    "os.makedirs(augmented_train_dir, exist_ok=True)\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "NUM_CLASSES = 5  \n",
    "EPOCHS = 50\n",
    "CONFIDENCE_THRESHOLD = 0.7\n",
    "AUGMENTATIONS_PER_IMAGE = 5 \n",
    "team = ['omar', 'ayat', 'mohammed', 'rana', 'unknown']\n",
    "\n",
    "def custom_augmentation(image):\n",
    "    noise = tf.random.normal(shape=tf.shape(image), mean=0.0, stddev=0.05)\n",
    "    image = image + noise\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "\n",
    "    if tf.random.uniform(()) > 0.5:\n",
    "        cutout_size = tf.random.uniform((), 20, 60, dtype=tf.int32)\n",
    "        h, w = IMG_SIZE\n",
    "        y = tf.random.uniform((), 0, h, dtype=tf.int32)\n",
    "        x = tf.random.uniform((), 0, w, dtype=tf.int32)\n",
    "        y1 = tf.clip_by_value(y - cutout_size // 2, 0, h)\n",
    "        y2 = tf.clip_by_value(y + cutout_size // 2, 0, h)\n",
    "        x1 = tf.clip_by_value(x - cutout_size // 2, 0, w)\n",
    "        x2 = tf.clip_by_value(x + cutout_size // 2, 0, w)\n",
    "        image = tf.image.crop_to_bounding_box(image, y1, x1, y2 - y1, x2 - x1)\n",
    "        image = tf.image.pad_to_bounding_box(image, y1, x1, h, w)\n",
    "    \n",
    "    return image\n",
    "\n",
    "augment_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.4,\n",
    "    height_shift_range=0.4,\n",
    "    shear_range=0.4,\n",
    "    zoom_range=[0.6, 1.4],\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.6, 1.4],\n",
    "    fill_mode='nearest',\n",
    "    preprocessing_function=custom_augmentation\n",
    ")\n",
    "\n",
    "def generate_augmented_images(input_dir, output_dir, classes, augmentations_per_image):\n",
    "    for class_name in classes:\n",
    "        class_input_dir = os.path.join(input_dir, class_name)\n",
    "        class_output_dir = os.path.join(output_dir, class_name)\n",
    "        os.makedirs(class_output_dir, exist_ok=True)\n",
    "\n",
    "        for img_name in os.listdir(class_input_dir):\n",
    "            img_path = os.path.join(class_input_dir, img_name)\n",
    "            try:\n",
    "                img = load_img(img_path, target_size=IMG_SIZE)\n",
    "                img_array = img_to_array(img)\n",
    "                img_array = img_array / 255.0  \n",
    "                img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "                for i in range(augmentations_per_image):\n",
    "                    aug_iter = augment_datagen.flow(img_array, batch_size=1)\n",
    "                    aug_img = next(aug_iter)[0]\n",
    "                    aug_img = (aug_img * 255).astype(np.uint8) \n",
    "                    aug_img_path = os.path.join(class_output_dir, f\"aug_{i}_{img_name}\")\n",
    "                    tf.keras.preprocessing.image.save_img(aug_img_path, aug_img)\n",
    "                    print(f\"Saved augmented image: {aug_img_path}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {img_path}: {e}\")\n",
    "\n",
    "if not os.path.exists(augmented_train_dir) or len(os.listdir(augmented_train_dir)) == 0:\n",
    "    print(\"Generating augmented images...\")\n",
    "    generate_augmented_images(train_dir, augmented_train_dir, team, AUGMENTATIONS_PER_IMAGE)\n",
    "else:\n",
    "    print(\"Augmented images already exist.\")\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.3,\n",
    "    height_shift_range=0.3,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.4,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    brightness_range=[0.7, 1.3],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    augmented_train_dir,  \n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=team,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_generator = val_test_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=team,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_generator = val_test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    classes=team,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "real_labels = train_generator.classes\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(real_labels), y=real_labels)\n",
    "class_weight_dict = dict(enumerate(class_weights))\n",
    "print(\"Class weights:\", class_weight_dict)\n",
    "\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu', kernel_regularizer=l2(0.01))(x)\n",
    "x = Dropout(0.6)(x)\n",
    "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "print(\"Model Summary:\")\n",
    "model.summary()\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    os.path.join(checkpoint_dir, 'attendance_checkpoint_epoch_{epoch:02d}.h5'),\n",
    "    save_weights_only=False,\n",
    "    save_best_only=False,\n",
    "    monitor='val_accuracy',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "steps_per_epoch = train_generator.samples // BATCH_SIZE\n",
    "validation_steps = val_generator.samples // BATCH_SIZE\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "model.trainable = True\n",
    "for layer in model.layers[:120]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=5e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_fine = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    initial_epoch=history.epoch[-1] + 1,\n",
    "    validation_data=val_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_steps=validation_steps,\n",
    "    class_weight=class_weight_dict,\n",
    "    callbacks=[checkpoint, early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n",
    "\n",
    "test_generator.reset()\n",
    "y_true = []\n",
    "y_pred = []\n",
    "for i in range(len(test_generator)):\n",
    "    images, labels = next(test_generator)\n",
    "    predictions = model.predict(images)\n",
    "    for pred in predictions:\n",
    "        if np.max(pred) < CONFIDENCE_THRESHOLD:\n",
    "            y_pred.append(4)  \n",
    "        else:\n",
    "            y_pred.append(np.argmax(pred))\n",
    "    y_true.extend(np.argmax(labels, axis=1))\n",
    "\n",
    "class_names = team\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))\n",
    "\n",
    "final_model_path = os.path.join(checkpoint_dir, 'attendance_mobilenetv2_final.h5')\n",
    "model.save(final_model_path)\n",
    "\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'] + history_fine.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'] + history_fine.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'] + history_fine.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'] + history_fine.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(checkpoint_dir, 'training_history.png'))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
